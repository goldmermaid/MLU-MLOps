{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress Testing on the End-to-end MLOps Pipeline\n",
    "\n",
    "The idea of this code is to see how the production Endpoint will behave when a **bunch** of requests arrive it.\n",
    "Let's simulate several users doing predictions at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import boto3\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "endpoint_name_mask='iris-model-%s'\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "def predict(payload):\n",
    "    csv_serializer = CSVSerializer()\n",
    "    payload = payload\n",
    "    X = payload[1:]\n",
    "    y = payload[0]\n",
    "    \n",
    "    elapsed_time = time.time()\n",
    "    resp = sm.invoke_endpoint(\n",
    "        EndpointName=endpoint_name_mask % env,\n",
    "        ContentType='text/csv',\n",
    "        Accept='text/csv',\n",
    "        Body=csv_serializer.serialize(X)\n",
    "    )\n",
    "    elapsed_time = time.time() - elapsed_time\n",
    "    resp = float(resp['Body'].read().decode('utf-8').strip())\n",
    "    return (resp == y, elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(max_threads, max_requests):\n",
    "    num_batches = math.ceil(max_requests / len(dataset))\n",
    "    requests = []\n",
    "    for i in range(num_batches):\n",
    "        batch = dataset.copy()\n",
    "        np.random.shuffle(batch)\n",
    "        requests += batch.tolist()\n",
    "    len(requests)\n",
    "\n",
    "    pool = ThreadPool(max_threads)\n",
    "    result = pool.map(predict, requests)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    correct_random_forest=0\n",
    "    elapsedtime_random_forest=0\n",
    "    for i in result:\n",
    "        correct_random_forest += i[0]\n",
    "        elapsedtime_random_forest += i[1]\n",
    "    print(\"Score classifier: {}\".format(correct_random_forest/len(result)))\n",
    "\n",
    "    print(\"Elapsed time: {}s\".format(elapsedtime_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env='production'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting test 1\")\n",
    "run_test(10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting test 2\")\n",
    "run_test(100, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following cell may take a long time to run. Once you get the \"**Alarm**\" (showing in pictures below), you can stop the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting test 3\")\n",
    "run_test(150, 100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action:** While this test is running, go to Amazon Sagemaker and click on the **Endpoint `iris-model-production`** and then click on the `View Logs` in **CloudWatch**` to see the Endpoint Behavior.\n",
    "\n",
    "1. Under CloudWatch `Metrics`, click the following \"Metric Name\": Invocations, InvocationsPerInstance and OverheadLatency (as showing below).\n",
    "<img src=\"../../imgs/cloudwatch_all_metrics.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "1. Then click `Graphed metrics` and modify the unit of \"Statistics\", \"Peroid\" and \"Y Axis\" as below. \n",
    "<img src=\"../../imgs/cloudwatch_graphed_metrics.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In CloudWatch, mark the following three checkboxes\n",
    "![CloudWatchA](../../imgs/CloudWatchA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, change the following config, marked in RED\n",
    "\n",
    "![CloudWatchB](../../imgs/CloudWatchB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, while your stress test is still running, you will see the Auto Scaling Alarm like this, after 3 datapoints above 750 Invocations Per Instance\n",
    "\n",
    "![CloudWatchC](../../imgs/CloudWatchC.png)\n",
    "\n",
    "When this happens, the Endpoint Autoscaling will start adding more instances to your cluster. You can observe in the Graph from the previous image that, after new instances are added to the cluster, the **Invocations** metrics grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
