{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3/4 - Batch Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch transform job\n",
    "If you have a file with the samples you want to predict, just upload that file to an S3 bucket and start a Batch Transform job. For this task, you don't need to deploy an endpoint. Sagemaker will create all the resources needed to do this batch prediction, save the results into an S3 bucket and then it will destroy the resources automatically for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn import datasets\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "prefix='mlops/iris'\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "model_name = open('model_name.txt', 'r').read().strip() if os.path.isfile('model_name.txt') else None\n",
    "if model_name is None:\n",
    "    raise Exception(\"You must run Part 1 or 2 before this. There you will train a Model to use here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataset_filename=\"batch_dataset.csv\"\n",
    "np.savetxt(batch_dataset_filename, iris.data, delimiter=\",\", fmt='%0.3f')\n",
    "input_batch = sagemaker_session.upload_data(path=batch_dataset_filename, key_prefix='%s/data' % prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[32m2020-12-14T22:44:56.719:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:54:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:54:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/12/14 22:44:54 [crit] 18#18: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/12/14 22:44:54 [crit] 18#18: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:56:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"POST /invocations HTTP/1.1\" 200 600 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2020/12/14 22:44:54 [crit] 18#18: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/12/14 22:44:54 [crit] 18#18: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:56:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"POST /invocations HTTP/1.1\" 200 600 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[32m2020-12-14T22:44:56.719:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:54:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:54:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/12/14 22:44:54 [crit] 18#18: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/12/14 22:44:54 [crit] 18#18: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2020-12-14 22:44:54 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-12-14:22:44:56:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"POST /invocations HTTP/1.1\" 200 600 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2020/12/14 22:44:54 [crit] 18#18: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/12/14 22:44:54 [crit] 18#18: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[35m[2020-12-14 22:44:54 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:56:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-12-14:22:44:56:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [14/Dec/2020:22:44:56 +0000] \"POST /invocations HTTP/1.1\" 200 600 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "CPU times: user 805 ms, sys: 18.2 ms, total: 823 ms\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize the transformer object\n",
    "transformer=sagemaker.transformer.Transformer(\n",
    "    base_transform_job_name='mlops-iris',\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    output_path='s3://{}/{}/batch_output'.format(bucket, prefix),\n",
    ")\n",
    "# To start a transform job:\n",
    "transformer.transform(input_batch, content_type='text/csv', split_type='Line')\n",
    "# Then wait until transform job is completed\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iris_id</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>predicted_iris_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iris_id  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0      0.0                5.1               3.5                1.4   \n",
       "1      0.0                4.9               3.0                1.4   \n",
       "2      0.0                4.7               3.2                1.3   \n",
       "3      0.0                4.6               3.1                1.5   \n",
       "4      0.0                5.0               3.6                1.4   \n",
       "\n",
       "   petal width (cm)  predicted_iris_id  \n",
       "0               0.2                0.0  \n",
       "1               0.2                0.0  \n",
       "2               0.2                0.0  \n",
       "3               0.2                0.0  \n",
       "4               0.2                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "df = pd.DataFrame(data=dataset, columns=['iris_id'] + iris.feature_names)\n",
    "df_pred = pd.read_csv(\n",
    "    io.StringIO(sagemaker_session.read_s3_file(bucket, '{}/batch_output/{}.out'.format(\n",
    "        prefix, batch_dataset_filename))), names=['predicted_iris_id'] )\n",
    "df = pd.merge(df,df_pred, left_index=True, right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score(micro): 97.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score = f1_score(df['iris_id'], df['predicted_iris_id'],labels=[0.0,1.0,2.0],average='micro')\n",
    "\n",
    "print('F1 Score(micro): %.1f' % (score * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0da1c355f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(df['iris_id'], df['predicted_iris_id'])\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 8))\n",
    "sns.heatmap(cnf_matrix, annot=True, fmt=\"f\", mask=np.zeros_like(cnf_matrix, dtype=np.bool), \n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alright, now that you know how to run a batch prediction ...\n",
    "\n",
    "Click [here to start the Part 4/4](04_BasicModel_Part4_ModelMonitoring.ipynb) of this warmup: Model Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
