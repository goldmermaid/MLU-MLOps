{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4/4 - Enabling Monitoring and checking violations\n",
    "\n",
    "In this exercise, we will enable [Model Monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) for the endpoint we created in the first part. This is an important feature if you need to keep an eye on the your model performance. You check for violations like: invalid input, data drift and more.\n",
    "\n",
    "You start this process by preparing the baseline or a reference set of statistic values that Monitor uses to compare with the payload and identify anomalies.  \n",
    "\n",
    "There is a cron job like called Monitoring Schedulle. This element will keep processing the logs (in and out) to create the reports you can see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "role = get_execution_role()\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "dataset = np.insert(X, 0, y,axis=1)\n",
    "pd.DataFrame(data=dataset, columns=['iris_id'] + iris.feature_names).to_csv('full_dataset.csv', index=None)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "prefix='mlops/iris'\n",
    "endpoint_name = open('endpoint_name.txt', 'r').read().strip() if os.path.isfile('endpoint_name.txt') else None\n",
    "endpoint_name2 = open('endpoint_name2.txt', 'r').read().strip() if os.path.isfile('endpoint_name2.txt') else None\n",
    "\n",
    "try:\n",
    "    xgb_predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)\n",
    "    xgb_predictor.serializer = CSVSerializer()\n",
    "except Exception as e:\n",
    "    raise Exception(\"You must run Part 1 before this. There, you will train/deploy a Model and use it here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2020-12-02-22-40-39-775\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-757420736997/model-monitor/baselining/baseline-suggestion-job-2020-12-02-22-40-39-775/input/baseline_dataset_input', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-757420736997/mlops/iris/monitoring/baseline', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...............................................................!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f969043c278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "endpoint_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "endpoint_monitor.suggest_baseline(\n",
    "    baseline_dataset='full_dataset.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri='s3://{}/{}/monitoring/baseline'.format(bucket, prefix),\n",
    "    wait=True,\n",
    "    logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just take a look on the baseline created/suggested by SageMaker for your dataset\n",
    "This set of statistics and constraints will be used by the Monitoring Scheduler to compare the incoming data with what is considered **normal**. Each invalid payload sent to the endpoint will be considered a violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris_id</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>5.843333</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>458.6</td>\n",
       "      <td>0.434411</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>563.7</td>\n",
       "      <td>1.759404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>179.9</td>\n",
       "      <td>0.759693</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0            iris_id    Fractional                                      150   \n",
       "1  sepal length (cm)    Fractional                                      150   \n",
       "2   sepal width (cm)    Fractional                                      150   \n",
       "3  petal length (cm)    Fractional                                      150   \n",
       "4   petal width (cm)    Fractional                                      150   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                   1.000000   \n",
       "1                                        0                   5.843333   \n",
       "2                                        0                   3.057333   \n",
       "3                                        0                   3.758000   \n",
       "4                                        0                   1.199333   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                     150.0                      0.816497   \n",
       "1                     876.5                      0.825301   \n",
       "2                     458.6                      0.434411   \n",
       "3                     563.7                      1.759404   \n",
       "4                     179.9                      0.759693   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                       0.0                       2.0   \n",
       "1                       4.3                       7.9   \n",
       "2                       2.0                       4.4   \n",
       "3                       1.0                       6.9   \n",
       "4                       0.1                       2.5   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  completeness  \\\n",
       "0                                             2048.0                   1.0   \n",
       "1                                             2048.0                   1.0   \n",
       "2                                             2048.0                   1.0   \n",
       "3                                             2048.0                   1.0   \n",
       "4                                             2048.0                   1.0   \n",
       "\n",
       "   num_constraints.is_non_negative  \n",
       "0                             True  \n",
       "1                             True  \n",
       "2                             True  \n",
       "3                             True  \n",
       "4                             True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_job = endpoint_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "constraints_df = pd.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "report_df = schema_df.merge(constraints_df)\n",
    "report_df.drop([\n",
    "    'numerical_statistics.distribution.kll.buckets',\n",
    "    'numerical_statistics.distribution.kll.sketch.data',\n",
    "    'numerical_statistics.distribution.kll.sketch.parameters.c'\n",
    "], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we need to create a **Monitoring Schedule** for our endpoint. The command below will create a cron scheduler that will process the log each hour, then we can see how well our model is going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Monitoring Schedule with name: monitoring-schedule-2020-12-02-22-53-14-346\n",
      "CPU times: user 55.3 ms, sys: 0 ns, total: 55.3 ms\n",
      "Wall time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_monitor.create_monitoring_schedule(\n",
    "    endpoint_input=endpoint_name,\n",
    "    output_s3_uri='s3://{}/{}/monitoring/reports'.format(bucket, prefix),\n",
    "    statistics=endpoint_monitor.baseline_statistics(),\n",
    "    constraints=endpoint_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MonitoringScheduleSummaries\": [\n",
      "        {\n",
      "            \"MonitoringScheduleName\": \"monitoring-schedule-2020-12-02-22-53-14-346\",\n",
      "            \"MonitoringScheduleArn\": \"arn:aws:sagemaker:us-east-1:757420736997:monitoring-schedule/monitoring-schedule-2020-12-02-22-53-14-346\",\n",
      "            \"CreationTime\": 1606949594.419,\n",
      "            \"LastModifiedTime\": 1606949594.446,\n",
      "            \"MonitoringScheduleStatus\": \"Pending\",\n",
      "            \"EndpointName\": \"sagemaker-xgboost-2020-12-02-22-11-17-882\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This is how you can list all the monitoring schedules you created in your account\n",
    "!aws sagemaker list-monitoring-schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start generating some artificial traffic\n",
    "The cell below starts a thread to send some traffic to the endpoint. Note that you need to stop the kernel to terminate this thread. If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking endpoint forever!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "from threading import Thread\n",
    "\n",
    "traffic_generator_running=True\n",
    "def invoke_endpoint_forever():\n",
    "    print('Invoking endpoint forever!')\n",
    "    while traffic_generator_running:\n",
    "        ## This will create an invalid set of features\n",
    "        ## The idea is to violate two monitoring constraings: not_null and data_drift\n",
    "        null_idx = random.randint(0,3)\n",
    "        sample = [random.randint(500,2000) / 100.0 for i in range(4)]\n",
    "        sample[null_idx] = None\n",
    "        xgb_predictor.predict(sample)\n",
    "        time.sleep(0.5)\n",
    "    print('Endpoint invoker has stopped')\n",
    "Thread(target = invoke_endpoint_forever).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kick off a processing job to analyze the logs\n",
    "Since the Monitoring Scheduler will only run each full hour and we don't have that time to wait, let's kick off a processin job manually (that simulates what the scheduler does) and see the report with the violations our Thread above will cause to the endpoint with the random payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import boto3\n",
    "\n",
    "def process_monitoring_logs(endpoint_monitor):\n",
    "    sm = boto3.client('sagemaker')\n",
    "    now = datetime.datetime.today()\n",
    "    suffix = now.strftime(\"%Y/%m/%d/%H\")\n",
    "    \n",
    "    start_time = datetime.datetime(now.year, now.month, now.day, now.hour)\n",
    "    end_time = start_time + datetime.timedelta(hours=1)\n",
    "    # get the monitoring metadata\n",
    "    desc = endpoint_monitor.describe_schedule()\n",
    "    monjob_desc = desc['MonitoringScheduleConfig']['MonitoringJobDefinition']\n",
    "    monjob_inputs = monjob_desc['MonitoringInputs'][0]['EndpointInput']\n",
    "    endpoint_name = desc['EndpointName']\n",
    "    variant_name = sm.describe_endpoint(EndpointName=endpoint_name)['ProductionVariants'][0]['VariantName']\n",
    "    logs_path = \"%s/%s/%s\" % (endpoint_name,variant_name,suffix)\n",
    "    s3_output = monjob_desc['MonitoringOutputConfig']['MonitoringOutputs'][0]['S3Output'].copy()\n",
    "    s3_output['S3Uri'] = \"%s/%s/%s/%s\" % (s3_output['S3Uri'], endpoint_name, desc['MonitoringScheduleName'], suffix)\n",
    "    # values for the processing job input\n",
    "    values = [\n",
    "        [ 'input_1', 's3://{}/{}/monitoring/{}'.format(bucket, prefix, logs_path),\n",
    "            '/opt/ml/processing/input/endpoint/{}'.format(logs_path) ], \n",
    "        [ 'baseline', monjob_desc['BaselineConfig']['StatisticsResource']['S3Uri'],\n",
    "            '/opt/ml/processing/baseline/stats'],\n",
    "        [ 'constraints', monjob_desc['BaselineConfig']['ConstraintsResource']['S3Uri'],\n",
    "            '/opt/ml/processing/baseline/constraints']\n",
    "    ]\n",
    "    job_params = {\n",
    "        'ProcessingJobName': 'model-monitoring-%s' % time.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        'ProcessingInputs': [{\n",
    "            'InputName': o[0],\n",
    "            'S3Input': { \n",
    "                'S3Uri': o[1], 'LocalPath': o[2], 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', \n",
    "                'S3CompressionType': 'None', 'S3DataDistributionType': 'FullyReplicated'\n",
    "            }} for o in values],\n",
    "        'ProcessingOutputConfig': { 'Outputs': [ {'OutputName': 'result','S3Output': s3_output } ] },\n",
    "        'ProcessingResources': monjob_desc['MonitoringResources'],\n",
    "        'AppSpecification': monjob_desc['MonitoringAppSpecification'],\n",
    "        'RoleArn': monjob_desc['RoleArn'],\n",
    "        'Environment': {\n",
    "            'baseline_constraints': '/opt/ml/processing/baseline/constraints/constraints.json',\n",
    "            'baseline_statistics': '/opt/ml/processing/baseline/stats/statistics.json',\n",
    "            'dataset_format': '{\"sagemakerCaptureJson\":{\"captureIndexNames\":[\"endpointInput\",\"endpointOutput\"]}}',\n",
    "            'dataset_source': '/opt/ml/processing/input/endpoint',      \n",
    "            'output_path': '/opt/ml/processing/output',\n",
    "            'publish_cloudwatch_metrics': 'Enabled',\n",
    "            'sagemaker_monitoring_schedule_name': desc['MonitoringScheduleName'],\n",
    "            'sagemaker_endpoint_name': endpoint_name,\n",
    "            'start_time': start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            'end_time': end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        }\n",
    "    }\n",
    "    sm.create_processing_job(**job_params)\n",
    "    waiter = sm.get_waiter('processing_job_completed_or_stopped')\n",
    "    waiter.wait( ProcessingJobName=job_params['ProcessingJobName'], WaiterConfig={'Delay': 30,'MaxAttempts': 20} )\n",
    "    return job_params['ProcessingJobName'], s3_output['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>completeness_check</td>\n",
       "      <td>Data completeness requirement is not met. Expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>completeness_check</td>\n",
       "      <td>Data completeness requirement is not met. Expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>completeness_check</td>\n",
       "      <td>Data completeness requirement is not met. Expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>completeness_check</td>\n",
       "      <td>Data completeness requirement is not met. Expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>baseline_drift_check</td>\n",
       "      <td>Baseline drift distance: 0.397103974639045 exc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name constraint_check_type  \\\n",
       "0   sepal width (cm)    completeness_check   \n",
       "1   petal width (cm)    completeness_check   \n",
       "2  sepal length (cm)    completeness_check   \n",
       "3  petal length (cm)    completeness_check   \n",
       "4  sepal length (cm)  baseline_drift_check   \n",
       "\n",
       "                                         description  \n",
       "0  Data completeness requirement is not met. Expe...  \n",
       "1  Data completeness requirement is not met. Expe...  \n",
       "2  Data completeness requirement is not met. Expe...  \n",
       "3  Data completeness requirement is not met. Expe...  \n",
       "4  Baseline drift distance: 0.397103974639045 exc...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "## The processing job takes something like 5mins to run\n",
    "job_name, s3_output = process_monitoring_logs(endpoint_monitor)\n",
    "tokens = s3_output.split('/', 3)\n",
    "df = pd.read_json(sagemaker_session.read_s3_file(tokens[2], '%s/constraint_violations.json' % tokens[3]))\n",
    "df = pd.json_normalize(df.violations)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check these metrics on CloudWatch. Just open the CloudWatch console, click on **Metrics**, then select:\n",
    "    All -> aws/sagemaker/Endpoints/data-metrics -> Endpoint, MonitoringSchedule\n",
    "\n",
    "Use the *endpoint_monitor* name to filter the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_generator_running=False\n",
    "time.sleep(3)\n",
    "endpoint_monitor.delete_monitoring_schedule()\n",
    "time.sleep(10) # wait for 10 seconds before trying to delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    xgb_predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)\n",
    "    xgb_predictor.delete_endpoint()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "try:\n",
    "    xgb_predictor2 = sagemaker.predictor.Predictor(endpoint_name=endpoint_name2, sagemaker_session=sagemaker_session)\n",
    "    xgb_predictor2.delete_endpoint()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
